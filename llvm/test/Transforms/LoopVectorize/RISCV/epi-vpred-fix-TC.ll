; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -mtriple riscv64 -mattr +m,+a,+f,+d,+zepi -riscv-v-vector-bits-min=64 \
; RUN:    -scalable-vectorization=only -prefer-predicate-over-epilogue=predicate-dont-vectorize -S -O2 < %s -o - | FileCheck %s
; RUN: opt -mtriple riscv64 -mattr +m,+a,+f,+d,+zepi -riscv-v-vector-bits-min=64 -interleave-no-scalar-epilogue=true \
; RUN:    -scalable-vectorization=only -prefer-predicate-over-epilogue=predicate-dont-vectorize -S -O2 < %s -o - | FileCheck %s --check-prefix=INTERLEAVE

; ModuleID = 'simple-add-notail.c'
source_filename = "simple-add-notail.c"
target datalayout = "e-m:e-p:64:64-i64:64-i128:128-n64-S128-v128:128:128-v256:128:128-v512:128:128-v1024:128:128"
target triple = "riscv64-unknown-linux-gnu"

; Function Attrs: nofree norecurse nounwind
define dso_local void @notail(i32* noalias nocapture %c, i32* noalias nocapture readonly %a, i32* noalias nocapture readonly %b) local_unnamed_addr {
; CHECK-LABEL: @notail(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.vscale.i64()
; CHECK-NEXT:    [[TMP1:%.*]] = shl i64 [[TMP0]], 1
; CHECK-NEXT:    [[TMP2:%.*]] = icmp ugt i64 [[TMP1]], -32001
; CHECK-NEXT:    br i1 [[TMP2]], label [[FOR_BODY:%.*]], label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ], [ 0, [[ENTRY:%.*]] ]
; CHECK-NEXT:    [[TMP3:%.*]] = sub i64 32000, [[INDEX]]
; CHECK-NEXT:    [[TMP4:%.*]] = tail call i64 @llvm.epi.vsetvl(i64 [[TMP3]], i64 2, i64 0)
; CHECK-NEXT:    [[TMP5:%.*]] = trunc i64 [[TMP4]] to i32
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds i32, i32* [[A:%.*]], i64 [[INDEX]]
; CHECK-NEXT:    [[TMP7:%.*]] = bitcast i32* [[TMP6]] to <vscale x 2 x i32>*
; CHECK-NEXT:    [[VP_OP_LOAD:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.load.nxv2i32.p0nxv2i32(<vscale x 2 x i32>* [[TMP7]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP5]])
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr inbounds i32, i32* [[B:%.*]], i64 [[INDEX]]
; CHECK-NEXT:    [[TMP9:%.*]] = bitcast i32* [[TMP8]] to <vscale x 2 x i32>*
; CHECK-NEXT:    [[VP_OP_LOAD1:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.load.nxv2i32.p0nxv2i32(<vscale x 2 x i32>* [[TMP9]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP5]])
; CHECK-NEXT:    [[VP_OP:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.add.nxv2i32(<vscale x 2 x i32> [[VP_OP_LOAD1]], <vscale x 2 x i32> [[VP_OP_LOAD]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP5]])
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds i32, i32* [[C:%.*]], i64 [[INDEX]]
; CHECK-NEXT:    [[TMP11:%.*]] = bitcast i32* [[TMP10]] to <vscale x 2 x i32>*
; CHECK-NEXT:    tail call void @llvm.vp.store.nxv2i32.p0nxv2i32(<vscale x 2 x i32> [[VP_OP]], <vscale x 2 x i32>* [[TMP11]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP5]])
; CHECK-NEXT:    [[TMP12:%.*]] = and i64 [[TMP4]], 4294967295
; CHECK-NEXT:    [[INDEX_NEXT]] = add i64 [[INDEX]], [[TMP12]]
; CHECK-NEXT:    [[TMP13:%.*]] = icmp eq i64 [[INDEX_NEXT]], 32000
; CHECK-NEXT:    br i1 [[TMP13]], label [[FOR_END:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
; CHECK:       for.body:
; CHECK-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ [[INDVARS_IV_NEXT:%.*]], [[FOR_BODY]] ], [ 0, [[ENTRY]] ]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds i32, i32* [[A]], i64 [[INDVARS_IV]]
; CHECK-NEXT:    [[TMP14:%.*]] = load i32, i32* [[ARRAYIDX]], align 4
; CHECK-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds i32, i32* [[B]], i64 [[INDVARS_IV]]
; CHECK-NEXT:    [[TMP15:%.*]] = load i32, i32* [[ARRAYIDX2]], align 4
; CHECK-NEXT:    [[ADD:%.*]] = add nsw i32 [[TMP15]], [[TMP14]]
; CHECK-NEXT:    [[ARRAYIDX4:%.*]] = getelementptr inbounds i32, i32* [[C]], i64 [[INDVARS_IV]]
; CHECK-NEXT:    store i32 [[ADD]], i32* [[ARRAYIDX4]], align 4
; CHECK-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
; CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], 32000
; CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[FOR_END]], label [[FOR_BODY]], !llvm.loop [[LOOP2:![0-9]+]]
; CHECK:       for.end:
; CHECK-NEXT:    ret void
;
; INTERLEAVE-LABEL: @notail(
; INTERLEAVE-NEXT:  entry:
; INTERLEAVE-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.vscale.i64()
; INTERLEAVE-NEXT:    [[TMP1:%.*]] = shl i64 [[TMP0]], 4
; INTERLEAVE-NEXT:    [[TMP2:%.*]] = icmp ugt i64 [[TMP1]], -32001
; INTERLEAVE-NEXT:    br i1 [[TMP2]], label [[FOR_BODY:%.*]], label [[VECTOR_BODY_PREHEADER:%.*]]
; INTERLEAVE:       vector.body.preheader:
; INTERLEAVE-NEXT:    [[TMP3:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP4:%.*]] = shl i32 [[TMP3]], 1
; INTERLEAVE-NEXT:    [[TMP5:%.*]] = sext i32 [[TMP4]] to i64
; INTERLEAVE-NEXT:    [[TMP6:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP7:%.*]] = shl i32 [[TMP6]], 2
; INTERLEAVE-NEXT:    [[TMP8:%.*]] = sext i32 [[TMP7]] to i64
; INTERLEAVE-NEXT:    [[TMP9:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP10:%.*]] = mul i32 [[TMP9]], 6
; INTERLEAVE-NEXT:    [[TMP11:%.*]] = sext i32 [[TMP10]] to i64
; INTERLEAVE-NEXT:    [[TMP12:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP13:%.*]] = shl i32 [[TMP12]], 3
; INTERLEAVE-NEXT:    [[TMP14:%.*]] = sext i32 [[TMP13]] to i64
; INTERLEAVE-NEXT:    [[TMP15:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP16:%.*]] = mul i32 [[TMP15]], 10
; INTERLEAVE-NEXT:    [[TMP17:%.*]] = sext i32 [[TMP16]] to i64
; INTERLEAVE-NEXT:    [[TMP18:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP19:%.*]] = mul i32 [[TMP18]], 12
; INTERLEAVE-NEXT:    [[TMP20:%.*]] = sext i32 [[TMP19]] to i64
; INTERLEAVE-NEXT:    [[TMP21:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP22:%.*]] = mul i32 [[TMP21]], 14
; INTERLEAVE-NEXT:    [[TMP23:%.*]] = sext i32 [[TMP22]] to i64
; INTERLEAVE-NEXT:    [[TMP24:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP25:%.*]] = shl i32 [[TMP24]], 1
; INTERLEAVE-NEXT:    [[TMP26:%.*]] = sext i32 [[TMP25]] to i64
; INTERLEAVE-NEXT:    [[TMP27:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP28:%.*]] = shl i32 [[TMP27]], 2
; INTERLEAVE-NEXT:    [[TMP29:%.*]] = sext i32 [[TMP28]] to i64
; INTERLEAVE-NEXT:    [[TMP30:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP31:%.*]] = mul i32 [[TMP30]], 6
; INTERLEAVE-NEXT:    [[TMP32:%.*]] = sext i32 [[TMP31]] to i64
; INTERLEAVE-NEXT:    [[TMP33:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP34:%.*]] = shl i32 [[TMP33]], 3
; INTERLEAVE-NEXT:    [[TMP35:%.*]] = sext i32 [[TMP34]] to i64
; INTERLEAVE-NEXT:    [[TMP36:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP37:%.*]] = mul i32 [[TMP36]], 10
; INTERLEAVE-NEXT:    [[TMP38:%.*]] = sext i32 [[TMP37]] to i64
; INTERLEAVE-NEXT:    [[TMP39:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP40:%.*]] = mul i32 [[TMP39]], 12
; INTERLEAVE-NEXT:    [[TMP41:%.*]] = sext i32 [[TMP40]] to i64
; INTERLEAVE-NEXT:    [[TMP42:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP43:%.*]] = mul i32 [[TMP42]], 14
; INTERLEAVE-NEXT:    [[TMP44:%.*]] = sext i32 [[TMP43]] to i64
; INTERLEAVE-NEXT:    [[TMP45:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP46:%.*]] = shl i32 [[TMP45]], 1
; INTERLEAVE-NEXT:    [[TMP47:%.*]] = sext i32 [[TMP46]] to i64
; INTERLEAVE-NEXT:    [[TMP48:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP49:%.*]] = shl i32 [[TMP48]], 2
; INTERLEAVE-NEXT:    [[TMP50:%.*]] = sext i32 [[TMP49]] to i64
; INTERLEAVE-NEXT:    [[TMP51:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP52:%.*]] = mul i32 [[TMP51]], 6
; INTERLEAVE-NEXT:    [[TMP53:%.*]] = sext i32 [[TMP52]] to i64
; INTERLEAVE-NEXT:    [[TMP54:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP55:%.*]] = shl i32 [[TMP54]], 3
; INTERLEAVE-NEXT:    [[TMP56:%.*]] = sext i32 [[TMP55]] to i64
; INTERLEAVE-NEXT:    [[TMP57:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP58:%.*]] = mul i32 [[TMP57]], 10
; INTERLEAVE-NEXT:    [[TMP59:%.*]] = sext i32 [[TMP58]] to i64
; INTERLEAVE-NEXT:    [[TMP60:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP61:%.*]] = mul i32 [[TMP60]], 12
; INTERLEAVE-NEXT:    [[TMP62:%.*]] = sext i32 [[TMP61]] to i64
; INTERLEAVE-NEXT:    [[TMP63:%.*]] = tail call i32 @llvm.vscale.i32()
; INTERLEAVE-NEXT:    [[TMP64:%.*]] = mul i32 [[TMP63]], 14
; INTERLEAVE-NEXT:    [[TMP65:%.*]] = sext i32 [[TMP64]] to i64
; INTERLEAVE-NEXT:    br label [[VECTOR_BODY:%.*]]
; INTERLEAVE:       vector.body:
; INTERLEAVE-NEXT:    [[INDEX:%.*]] = phi i64 [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ], [ 0, [[VECTOR_BODY_PREHEADER]] ]
; INTERLEAVE-NEXT:    [[TMP66:%.*]] = sub i64 32000, [[INDEX]]
; INTERLEAVE-NEXT:    [[TMP67:%.*]] = tail call i64 @llvm.epi.vsetvl(i64 [[TMP66]], i64 2, i64 0)
; INTERLEAVE-NEXT:    [[TMP68:%.*]] = trunc i64 [[TMP67]] to i32
; INTERLEAVE-NEXT:    [[TMP69:%.*]] = sub i64 [[TMP66]], [[TMP67]]
; INTERLEAVE-NEXT:    [[TMP70:%.*]] = tail call i64 @llvm.epi.vsetvl(i64 [[TMP69]], i64 2, i64 0)
; INTERLEAVE-NEXT:    [[TMP71:%.*]] = trunc i64 [[TMP70]] to i32
; INTERLEAVE-NEXT:    [[TMP72:%.*]] = sub i64 [[TMP69]], [[TMP70]]
; INTERLEAVE-NEXT:    [[TMP73:%.*]] = tail call i64 @llvm.epi.vsetvl(i64 [[TMP72]], i64 2, i64 0)
; INTERLEAVE-NEXT:    [[TMP74:%.*]] = trunc i64 [[TMP73]] to i32
; INTERLEAVE-NEXT:    [[TMP75:%.*]] = sub i64 [[TMP72]], [[TMP73]]
; INTERLEAVE-NEXT:    [[TMP76:%.*]] = tail call i64 @llvm.epi.vsetvl(i64 [[TMP75]], i64 2, i64 0)
; INTERLEAVE-NEXT:    [[TMP77:%.*]] = trunc i64 [[TMP76]] to i32
; INTERLEAVE-NEXT:    [[TMP78:%.*]] = sub i64 [[TMP75]], [[TMP76]]
; INTERLEAVE-NEXT:    [[TMP79:%.*]] = tail call i64 @llvm.epi.vsetvl(i64 [[TMP78]], i64 2, i64 0)
; INTERLEAVE-NEXT:    [[TMP80:%.*]] = trunc i64 [[TMP79]] to i32
; INTERLEAVE-NEXT:    [[TMP81:%.*]] = sub i64 [[TMP78]], [[TMP79]]
; INTERLEAVE-NEXT:    [[TMP82:%.*]] = tail call i64 @llvm.epi.vsetvl(i64 [[TMP81]], i64 2, i64 0)
; INTERLEAVE-NEXT:    [[TMP83:%.*]] = trunc i64 [[TMP82]] to i32
; INTERLEAVE-NEXT:    [[TMP84:%.*]] = sub i64 [[TMP81]], [[TMP82]]
; INTERLEAVE-NEXT:    [[TMP85:%.*]] = tail call i64 @llvm.epi.vsetvl(i64 [[TMP84]], i64 2, i64 0)
; INTERLEAVE-NEXT:    [[TMP86:%.*]] = trunc i64 [[TMP85]] to i32
; INTERLEAVE-NEXT:    [[TMP87:%.*]] = sub i64 [[TMP84]], [[TMP85]]
; INTERLEAVE-NEXT:    [[TMP88:%.*]] = tail call i64 @llvm.epi.vsetvl(i64 [[TMP87]], i64 2, i64 0)
; INTERLEAVE-NEXT:    [[TMP89:%.*]] = trunc i64 [[TMP88]] to i32
; INTERLEAVE-NEXT:    [[TMP90:%.*]] = getelementptr inbounds i32, i32* [[A:%.*]], i64 [[INDEX]]
; INTERLEAVE-NEXT:    [[TMP91:%.*]] = bitcast i32* [[TMP90]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    [[VP_OP_LOAD:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.load.nxv2i32.p0nxv2i32(<vscale x 2 x i32>* [[TMP91]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP68]])
; INTERLEAVE-NEXT:    [[TMP92:%.*]] = getelementptr inbounds i32, i32* [[TMP90]], i64 [[TMP5]]
; INTERLEAVE-NEXT:    [[TMP93:%.*]] = bitcast i32* [[TMP92]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    [[VP_OP_LOAD20:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.load.nxv2i32.p0nxv2i32(<vscale x 2 x i32>* [[TMP93]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP71]])
; INTERLEAVE-NEXT:    [[TMP94:%.*]] = getelementptr inbounds i32, i32* [[TMP90]], i64 [[TMP8]]
; INTERLEAVE-NEXT:    [[TMP95:%.*]] = bitcast i32* [[TMP94]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    [[VP_OP_LOAD21:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.load.nxv2i32.p0nxv2i32(<vscale x 2 x i32>* [[TMP95]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP74]])
; INTERLEAVE-NEXT:    [[TMP96:%.*]] = getelementptr inbounds i32, i32* [[TMP90]], i64 [[TMP11]]
; INTERLEAVE-NEXT:    [[TMP97:%.*]] = bitcast i32* [[TMP96]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    [[VP_OP_LOAD22:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.load.nxv2i32.p0nxv2i32(<vscale x 2 x i32>* [[TMP97]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP77]])
; INTERLEAVE-NEXT:    [[TMP98:%.*]] = getelementptr inbounds i32, i32* [[TMP90]], i64 [[TMP14]]
; INTERLEAVE-NEXT:    [[TMP99:%.*]] = bitcast i32* [[TMP98]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    [[VP_OP_LOAD23:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.load.nxv2i32.p0nxv2i32(<vscale x 2 x i32>* [[TMP99]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP80]])
; INTERLEAVE-NEXT:    [[TMP100:%.*]] = getelementptr inbounds i32, i32* [[TMP90]], i64 [[TMP17]]
; INTERLEAVE-NEXT:    [[TMP101:%.*]] = bitcast i32* [[TMP100]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    [[VP_OP_LOAD24:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.load.nxv2i32.p0nxv2i32(<vscale x 2 x i32>* [[TMP101]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP83]])
; INTERLEAVE-NEXT:    [[TMP102:%.*]] = getelementptr inbounds i32, i32* [[TMP90]], i64 [[TMP20]]
; INTERLEAVE-NEXT:    [[TMP103:%.*]] = bitcast i32* [[TMP102]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    [[VP_OP_LOAD25:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.load.nxv2i32.p0nxv2i32(<vscale x 2 x i32>* [[TMP103]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP86]])
; INTERLEAVE-NEXT:    [[TMP104:%.*]] = getelementptr inbounds i32, i32* [[TMP90]], i64 [[TMP23]]
; INTERLEAVE-NEXT:    [[TMP105:%.*]] = bitcast i32* [[TMP104]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    [[VP_OP_LOAD26:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.load.nxv2i32.p0nxv2i32(<vscale x 2 x i32>* [[TMP105]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP89]])
; INTERLEAVE-NEXT:    [[TMP106:%.*]] = getelementptr inbounds i32, i32* [[B:%.*]], i64 [[INDEX]]
; INTERLEAVE-NEXT:    [[TMP107:%.*]] = bitcast i32* [[TMP106]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    [[VP_OP_LOAD27:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.load.nxv2i32.p0nxv2i32(<vscale x 2 x i32>* [[TMP107]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP68]])
; INTERLEAVE-NEXT:    [[TMP108:%.*]] = getelementptr inbounds i32, i32* [[TMP106]], i64 [[TMP26]]
; INTERLEAVE-NEXT:    [[TMP109:%.*]] = bitcast i32* [[TMP108]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    [[VP_OP_LOAD28:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.load.nxv2i32.p0nxv2i32(<vscale x 2 x i32>* [[TMP109]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP71]])
; INTERLEAVE-NEXT:    [[TMP110:%.*]] = getelementptr inbounds i32, i32* [[TMP106]], i64 [[TMP29]]
; INTERLEAVE-NEXT:    [[TMP111:%.*]] = bitcast i32* [[TMP110]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    [[VP_OP_LOAD29:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.load.nxv2i32.p0nxv2i32(<vscale x 2 x i32>* [[TMP111]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP74]])
; INTERLEAVE-NEXT:    [[TMP112:%.*]] = getelementptr inbounds i32, i32* [[TMP106]], i64 [[TMP32]]
; INTERLEAVE-NEXT:    [[TMP113:%.*]] = bitcast i32* [[TMP112]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    [[VP_OP_LOAD30:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.load.nxv2i32.p0nxv2i32(<vscale x 2 x i32>* [[TMP113]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP77]])
; INTERLEAVE-NEXT:    [[TMP114:%.*]] = getelementptr inbounds i32, i32* [[TMP106]], i64 [[TMP35]]
; INTERLEAVE-NEXT:    [[TMP115:%.*]] = bitcast i32* [[TMP114]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    [[VP_OP_LOAD31:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.load.nxv2i32.p0nxv2i32(<vscale x 2 x i32>* [[TMP115]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP80]])
; INTERLEAVE-NEXT:    [[TMP116:%.*]] = getelementptr inbounds i32, i32* [[TMP106]], i64 [[TMP38]]
; INTERLEAVE-NEXT:    [[TMP117:%.*]] = bitcast i32* [[TMP116]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    [[VP_OP_LOAD32:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.load.nxv2i32.p0nxv2i32(<vscale x 2 x i32>* [[TMP117]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP83]])
; INTERLEAVE-NEXT:    [[TMP118:%.*]] = getelementptr inbounds i32, i32* [[TMP106]], i64 [[TMP41]]
; INTERLEAVE-NEXT:    [[TMP119:%.*]] = bitcast i32* [[TMP118]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    [[VP_OP_LOAD33:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.load.nxv2i32.p0nxv2i32(<vscale x 2 x i32>* [[TMP119]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP86]])
; INTERLEAVE-NEXT:    [[TMP120:%.*]] = getelementptr inbounds i32, i32* [[TMP106]], i64 [[TMP44]]
; INTERLEAVE-NEXT:    [[TMP121:%.*]] = bitcast i32* [[TMP120]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    [[VP_OP_LOAD34:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.load.nxv2i32.p0nxv2i32(<vscale x 2 x i32>* [[TMP121]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP89]])
; INTERLEAVE-NEXT:    [[VP_OP:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.add.nxv2i32(<vscale x 2 x i32> [[VP_OP_LOAD27]], <vscale x 2 x i32> [[VP_OP_LOAD]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP68]])
; INTERLEAVE-NEXT:    [[VP_OP35:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.add.nxv2i32(<vscale x 2 x i32> [[VP_OP_LOAD28]], <vscale x 2 x i32> [[VP_OP_LOAD20]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP71]])
; INTERLEAVE-NEXT:    [[VP_OP36:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.add.nxv2i32(<vscale x 2 x i32> [[VP_OP_LOAD29]], <vscale x 2 x i32> [[VP_OP_LOAD21]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP74]])
; INTERLEAVE-NEXT:    [[VP_OP37:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.add.nxv2i32(<vscale x 2 x i32> [[VP_OP_LOAD30]], <vscale x 2 x i32> [[VP_OP_LOAD22]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP77]])
; INTERLEAVE-NEXT:    [[VP_OP38:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.add.nxv2i32(<vscale x 2 x i32> [[VP_OP_LOAD31]], <vscale x 2 x i32> [[VP_OP_LOAD23]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP80]])
; INTERLEAVE-NEXT:    [[VP_OP39:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.add.nxv2i32(<vscale x 2 x i32> [[VP_OP_LOAD32]], <vscale x 2 x i32> [[VP_OP_LOAD24]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP83]])
; INTERLEAVE-NEXT:    [[VP_OP40:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.add.nxv2i32(<vscale x 2 x i32> [[VP_OP_LOAD33]], <vscale x 2 x i32> [[VP_OP_LOAD25]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP86]])
; INTERLEAVE-NEXT:    [[VP_OP41:%.*]] = tail call <vscale x 2 x i32> @llvm.vp.add.nxv2i32(<vscale x 2 x i32> [[VP_OP_LOAD34]], <vscale x 2 x i32> [[VP_OP_LOAD26]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP89]])
; INTERLEAVE-NEXT:    [[TMP122:%.*]] = getelementptr inbounds i32, i32* [[C:%.*]], i64 [[INDEX]]
; INTERLEAVE-NEXT:    [[TMP123:%.*]] = bitcast i32* [[TMP122]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    tail call void @llvm.vp.store.nxv2i32.p0nxv2i32(<vscale x 2 x i32> [[VP_OP]], <vscale x 2 x i32>* [[TMP123]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP68]])
; INTERLEAVE-NEXT:    [[TMP124:%.*]] = getelementptr inbounds i32, i32* [[TMP122]], i64 [[TMP47]]
; INTERLEAVE-NEXT:    [[TMP125:%.*]] = bitcast i32* [[TMP124]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    tail call void @llvm.vp.store.nxv2i32.p0nxv2i32(<vscale x 2 x i32> [[VP_OP35]], <vscale x 2 x i32>* [[TMP125]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP71]])
; INTERLEAVE-NEXT:    [[TMP126:%.*]] = getelementptr inbounds i32, i32* [[TMP122]], i64 [[TMP50]]
; INTERLEAVE-NEXT:    [[TMP127:%.*]] = bitcast i32* [[TMP126]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    tail call void @llvm.vp.store.nxv2i32.p0nxv2i32(<vscale x 2 x i32> [[VP_OP36]], <vscale x 2 x i32>* [[TMP127]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP74]])
; INTERLEAVE-NEXT:    [[TMP128:%.*]] = getelementptr inbounds i32, i32* [[TMP122]], i64 [[TMP53]]
; INTERLEAVE-NEXT:    [[TMP129:%.*]] = bitcast i32* [[TMP128]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    tail call void @llvm.vp.store.nxv2i32.p0nxv2i32(<vscale x 2 x i32> [[VP_OP37]], <vscale x 2 x i32>* [[TMP129]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP77]])
; INTERLEAVE-NEXT:    [[TMP130:%.*]] = getelementptr inbounds i32, i32* [[TMP122]], i64 [[TMP56]]
; INTERLEAVE-NEXT:    [[TMP131:%.*]] = bitcast i32* [[TMP130]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    tail call void @llvm.vp.store.nxv2i32.p0nxv2i32(<vscale x 2 x i32> [[VP_OP38]], <vscale x 2 x i32>* [[TMP131]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP80]])
; INTERLEAVE-NEXT:    [[TMP132:%.*]] = getelementptr inbounds i32, i32* [[TMP122]], i64 [[TMP59]]
; INTERLEAVE-NEXT:    [[TMP133:%.*]] = bitcast i32* [[TMP132]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    tail call void @llvm.vp.store.nxv2i32.p0nxv2i32(<vscale x 2 x i32> [[VP_OP39]], <vscale x 2 x i32>* [[TMP133]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP83]])
; INTERLEAVE-NEXT:    [[TMP134:%.*]] = getelementptr inbounds i32, i32* [[TMP122]], i64 [[TMP62]]
; INTERLEAVE-NEXT:    [[TMP135:%.*]] = bitcast i32* [[TMP134]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    tail call void @llvm.vp.store.nxv2i32.p0nxv2i32(<vscale x 2 x i32> [[VP_OP40]], <vscale x 2 x i32>* [[TMP135]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP86]])
; INTERLEAVE-NEXT:    [[TMP136:%.*]] = getelementptr inbounds i32, i32* [[TMP122]], i64 [[TMP65]]
; INTERLEAVE-NEXT:    [[TMP137:%.*]] = bitcast i32* [[TMP136]] to <vscale x 2 x i32>*
; INTERLEAVE-NEXT:    tail call void @llvm.vp.store.nxv2i32.p0nxv2i32(<vscale x 2 x i32> [[VP_OP41]], <vscale x 2 x i32>* [[TMP137]], <vscale x 2 x i1> shufflevector (<vscale x 2 x i1> insertelement (<vscale x 2 x i1> poison, i1 true, i32 0), <vscale x 2 x i1> poison, <vscale x 2 x i32> zeroinitializer), i32 [[TMP89]])
; INTERLEAVE-NEXT:    [[TMP138:%.*]] = add i64 [[TMP67]], [[TMP70]]
; INTERLEAVE-NEXT:    [[TMP139:%.*]] = add i64 [[TMP138]], [[TMP73]]
; INTERLEAVE-NEXT:    [[TMP140:%.*]] = add i64 [[TMP139]], [[TMP76]]
; INTERLEAVE-NEXT:    [[TMP141:%.*]] = add i64 [[TMP140]], [[TMP79]]
; INTERLEAVE-NEXT:    [[TMP142:%.*]] = add i64 [[TMP141]], [[TMP82]]
; INTERLEAVE-NEXT:    [[TMP143:%.*]] = add i64 [[TMP142]], [[TMP85]]
; INTERLEAVE-NEXT:    [[TMP144:%.*]] = add i64 [[TMP143]], [[TMP88]]
; INTERLEAVE-NEXT:    [[TMP145:%.*]] = and i64 [[TMP144]], 4294967295
; INTERLEAVE-NEXT:    [[INDEX_NEXT]] = add i64 [[INDEX]], [[TMP145]]
; INTERLEAVE-NEXT:    [[TMP146:%.*]] = icmp eq i64 [[INDEX_NEXT]], 32000
; INTERLEAVE-NEXT:    br i1 [[TMP146]], label [[FOR_END:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
; INTERLEAVE:       for.body:
; INTERLEAVE-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ [[INDVARS_IV_NEXT:%.*]], [[FOR_BODY]] ], [ 0, [[ENTRY:%.*]] ]
; INTERLEAVE-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds i32, i32* [[A]], i64 [[INDVARS_IV]]
; INTERLEAVE-NEXT:    [[TMP147:%.*]] = load i32, i32* [[ARRAYIDX]], align 4
; INTERLEAVE-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds i32, i32* [[B]], i64 [[INDVARS_IV]]
; INTERLEAVE-NEXT:    [[TMP148:%.*]] = load i32, i32* [[ARRAYIDX2]], align 4
; INTERLEAVE-NEXT:    [[ADD:%.*]] = add nsw i32 [[TMP148]], [[TMP147]]
; INTERLEAVE-NEXT:    [[ARRAYIDX4:%.*]] = getelementptr inbounds i32, i32* [[C]], i64 [[INDVARS_IV]]
; INTERLEAVE-NEXT:    store i32 [[ADD]], i32* [[ARRAYIDX4]], align 4
; INTERLEAVE-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
; INTERLEAVE-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[INDVARS_IV_NEXT]], 32000
; INTERLEAVE-NEXT:    br i1 [[EXITCOND_NOT]], label [[FOR_END]], label [[FOR_BODY]], !llvm.loop [[LOOP2:![0-9]+]]
; INTERLEAVE:       for.end:
; INTERLEAVE-NEXT:    ret void
;
entry:
  br label %for.body

for.body:                                         ; preds = %entry, %for.body
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds i32, i32* %a, i64 %indvars.iv
  %0 = load i32, i32* %arrayidx, align 4
  %arrayidx2 = getelementptr inbounds i32, i32* %b, i64 %indvars.iv
  %1 = load i32, i32* %arrayidx2, align 4
  %add = add nsw i32 %1, %0
  %arrayidx4 = getelementptr inbounds i32, i32* %c, i64 %indvars.iv
  store i32 %add, i32* %arrayidx4, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond.not = icmp eq i64 %indvars.iv.next, 32000
  br i1 %exitcond.not, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  ret void
}
