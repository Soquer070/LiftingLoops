// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -triple riscv64 -target-abi lp64 -emit-llvm %s -o - | FileCheck %s --check-prefix=RISCV64-LP64
// RUN: %clang_cc1 -triple riscv64 -target-abi lp64f -target-feature +hard-float-single -emit-llvm %s -o - | FileCheck %s --check-prefix=RISCV64-LP64F
// RUN: %clang_cc1 -triple riscv64 -target-abi lp64d -target-feature +hard-float-double -emit-llvm %s -o - | FileCheck %s --check-prefix=RISCV64-LP64D

struct pair_of_float_homogeneous_t {
  float a, b;
} a_pair_of_float_homogeneous;

void pair_of_float_homogeneous(struct pair_of_float_homogeneous_t);

// RISCV64-LP64-LABEL: @test_pair_of_float_homogeneous(
// RISCV64-LP64-NEXT:  entry:
// RISCV64-LP64-NEXT:    [[TMP0:%.*]] = load i64, i64* bitcast (%struct.pair_of_float_homogeneous_t* @a_pair_of_float_homogeneous to i64*), align 4
// RISCV64-LP64-NEXT:    call void @pair_of_float_homogeneous(i64 [[TMP0]])
// RISCV64-LP64-NEXT:    ret void
//
// RISCV64-LP64F-LABEL: @test_pair_of_float_homogeneous(
// RISCV64-LP64F-NEXT:  entry:
// RISCV64-LP64F-NEXT:    [[TMP0:%.*]] = load float, float* getelementptr inbounds (%0, %0* bitcast (%struct.pair_of_float_homogeneous_t* @a_pair_of_float_homogeneous to %0*), i32 0, i32 0), align 4
// RISCV64-LP64F-NEXT:    [[TMP1:%.*]] = load float, float* getelementptr inbounds (%0, %0* bitcast (%struct.pair_of_float_homogeneous_t* @a_pair_of_float_homogeneous to %0*), i32 0, i32 1), align 4
// RISCV64-LP64F-NEXT:    call void @pair_of_float_homogeneous(float [[TMP0]], float [[TMP1]])
// RISCV64-LP64F-NEXT:    ret void
//
// RISCV64-LP64D-LABEL: @test_pair_of_float_homogeneous(
// RISCV64-LP64D-NEXT:  entry:
// RISCV64-LP64D-NEXT:    [[TMP0:%.*]] = load float, float* getelementptr inbounds (%0, %0* bitcast (%struct.pair_of_float_homogeneous_t* @a_pair_of_float_homogeneous to %0*), i32 0, i32 0), align 4
// RISCV64-LP64D-NEXT:    [[TMP1:%.*]] = load float, float* getelementptr inbounds (%0, %0* bitcast (%struct.pair_of_float_homogeneous_t* @a_pair_of_float_homogeneous to %0*), i32 0, i32 1), align 4
// RISCV64-LP64D-NEXT:    call void @pair_of_float_homogeneous(float [[TMP0]], float [[TMP1]])
// RISCV64-LP64D-NEXT:    ret void
//
void test_pair_of_float_homogeneous(void) {
  pair_of_float_homogeneous(a_pair_of_float_homogeneous);
}

void last_still_ok_for_homogeneous_pair(float a1, float a2, float a3, float a4, float a5, float a6, struct pair_of_float_homogeneous_t);

// RISCV64-LP64-LABEL: @test_last_still_ok_for_homogeneous_pair(
// RISCV64-LP64-NEXT:  entry:
// RISCV64-LP64-NEXT:    [[TMP0:%.*]] = load i64, i64* bitcast (%struct.pair_of_float_homogeneous_t* @a_pair_of_float_homogeneous to i64*), align 4
// RISCV64-LP64-NEXT:    call void @last_still_ok_for_homogeneous_pair(float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, i64 [[TMP0]])
// RISCV64-LP64-NEXT:    ret void
//
// RISCV64-LP64F-LABEL: @test_last_still_ok_for_homogeneous_pair(
// RISCV64-LP64F-NEXT:  entry:
// RISCV64-LP64F-NEXT:    [[TMP0:%.*]] = load float, float* getelementptr inbounds (%1, %1* bitcast (%struct.pair_of_float_homogeneous_t* @a_pair_of_float_homogeneous to %1*), i32 0, i32 0), align 4
// RISCV64-LP64F-NEXT:    [[TMP1:%.*]] = load float, float* getelementptr inbounds (%1, %1* bitcast (%struct.pair_of_float_homogeneous_t* @a_pair_of_float_homogeneous to %1*), i32 0, i32 1), align 4
// RISCV64-LP64F-NEXT:    call void @last_still_ok_for_homogeneous_pair(float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float [[TMP0]], float [[TMP1]])
// RISCV64-LP64F-NEXT:    ret void
//
// RISCV64-LP64D-LABEL: @test_last_still_ok_for_homogeneous_pair(
// RISCV64-LP64D-NEXT:  entry:
// RISCV64-LP64D-NEXT:    [[TMP0:%.*]] = load float, float* getelementptr inbounds (%1, %1* bitcast (%struct.pair_of_float_homogeneous_t* @a_pair_of_float_homogeneous to %1*), i32 0, i32 0), align 4
// RISCV64-LP64D-NEXT:    [[TMP1:%.*]] = load float, float* getelementptr inbounds (%1, %1* bitcast (%struct.pair_of_float_homogeneous_t* @a_pair_of_float_homogeneous to %1*), i32 0, i32 1), align 4
// RISCV64-LP64D-NEXT:    call void @last_still_ok_for_homogeneous_pair(float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float [[TMP0]], float [[TMP1]])
// RISCV64-LP64D-NEXT:    ret void
//
void test_last_still_ok_for_homogeneous_pair(void) {
  last_still_ok_for_homogeneous_pair(0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f, a_pair_of_float_homogeneous);
}

void too_many_floats_1_for_homogeneous_pair(float a1, float a2, float a3, float a4, float a5, float a6, float a7, struct pair_of_float_homogeneous_t);

// RISCV64-LP64-LABEL: @test_too_many_floats_1_for_homogeneous_pair(
// RISCV64-LP64-NEXT:  entry:
// RISCV64-LP64-NEXT:    [[TMP0:%.*]] = load i64, i64* bitcast (%struct.pair_of_float_homogeneous_t* @a_pair_of_float_homogeneous to i64*), align 4
// RISCV64-LP64-NEXT:    call void @too_many_floats_1_for_homogeneous_pair(float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, i64 [[TMP0]])
// RISCV64-LP64-NEXT:    ret void
//
// RISCV64-LP64F-LABEL: @test_too_many_floats_1_for_homogeneous_pair(
// RISCV64-LP64F-NEXT:  entry:
// RISCV64-LP64F-NEXT:    [[TMP0:%.*]] = load i64, i64* bitcast (%struct.pair_of_float_homogeneous_t* @a_pair_of_float_homogeneous to i64*), align 4
// RISCV64-LP64F-NEXT:    call void @too_many_floats_1_for_homogeneous_pair(float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, i64 [[TMP0]])
// RISCV64-LP64F-NEXT:    ret void
//
// RISCV64-LP64D-LABEL: @test_too_many_floats_1_for_homogeneous_pair(
// RISCV64-LP64D-NEXT:  entry:
// RISCV64-LP64D-NEXT:    [[TMP0:%.*]] = load i64, i64* bitcast (%struct.pair_of_float_homogeneous_t* @a_pair_of_float_homogeneous to i64*), align 4
// RISCV64-LP64D-NEXT:    call void @too_many_floats_1_for_homogeneous_pair(float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, float 0.000000e+00, i64 [[TMP0]])
// RISCV64-LP64D-NEXT:    ret void
//
void test_too_many_floats_1_for_homogeneous_pair(void) {
  too_many_floats_1_for_homogeneous_pair(0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f, a_pair_of_float_homogeneous);
}

struct pair_of_float_nesting1_t {
  float a;
  struct {
    float b;
  };
} a_pair_of_float_nesting1;

void pair_of_float_nesting1(struct pair_of_float_nesting1_t);

// RISCV64-LP64-LABEL: @test_pair_of_float_nesting1(
// RISCV64-LP64-NEXT:  entry:
// RISCV64-LP64-NEXT:    [[TMP0:%.*]] = load i64, i64* bitcast (%struct.pair_of_float_nesting1_t* @a_pair_of_float_nesting1 to i64*), align 4
// RISCV64-LP64-NEXT:    call void @pair_of_float_nesting1(i64 [[TMP0]])
// RISCV64-LP64-NEXT:    ret void
//
// RISCV64-LP64F-LABEL: @test_pair_of_float_nesting1(
// RISCV64-LP64F-NEXT:  entry:
// RISCV64-LP64F-NEXT:    [[TMP0:%.*]] = load float, float* getelementptr inbounds (%2, %2* bitcast (%struct.pair_of_float_nesting1_t* @a_pair_of_float_nesting1 to %2*), i32 0, i32 0), align 4
// RISCV64-LP64F-NEXT:    [[TMP1:%.*]] = load float, float* getelementptr inbounds (%2, %2* bitcast (%struct.pair_of_float_nesting1_t* @a_pair_of_float_nesting1 to %2*), i32 0, i32 1), align 4
// RISCV64-LP64F-NEXT:    call void @pair_of_float_nesting1(float [[TMP0]], float [[TMP1]])
// RISCV64-LP64F-NEXT:    ret void
//
// RISCV64-LP64D-LABEL: @test_pair_of_float_nesting1(
// RISCV64-LP64D-NEXT:  entry:
// RISCV64-LP64D-NEXT:    [[TMP0:%.*]] = load float, float* getelementptr inbounds (%2, %2* bitcast (%struct.pair_of_float_nesting1_t* @a_pair_of_float_nesting1 to %2*), i32 0, i32 0), align 4
// RISCV64-LP64D-NEXT:    [[TMP1:%.*]] = load float, float* getelementptr inbounds (%2, %2* bitcast (%struct.pair_of_float_nesting1_t* @a_pair_of_float_nesting1 to %2*), i32 0, i32 1), align 4
// RISCV64-LP64D-NEXT:    call void @pair_of_float_nesting1(float [[TMP0]], float [[TMP1]])
// RISCV64-LP64D-NEXT:    ret void
//
void test_pair_of_float_nesting1(void) {
  pair_of_float_nesting1(a_pair_of_float_nesting1);
}

struct pair_of_float_nesting2_t {
  float a[2];
} a_pair_of_float_nesting2;

void pair_of_float_nesting2(struct pair_of_float_nesting2_t);

// RISCV64-LP64-LABEL: @test_pair_of_float_nesting2(
// RISCV64-LP64-NEXT:  entry:
// RISCV64-LP64-NEXT:    [[TMP0:%.*]] = load i64, i64* bitcast (%struct.pair_of_float_nesting2_t* @a_pair_of_float_nesting2 to i64*), align 4
// RISCV64-LP64-NEXT:    call void @pair_of_float_nesting2(i64 [[TMP0]])
// RISCV64-LP64-NEXT:    ret void
//
// RISCV64-LP64F-LABEL: @test_pair_of_float_nesting2(
// RISCV64-LP64F-NEXT:  entry:
// RISCV64-LP64F-NEXT:    [[TMP0:%.*]] = load float, float* getelementptr inbounds (%3, %3* bitcast (%struct.pair_of_float_nesting2_t* @a_pair_of_float_nesting2 to %3*), i32 0, i32 0), align 4
// RISCV64-LP64F-NEXT:    [[TMP1:%.*]] = load float, float* getelementptr inbounds (%3, %3* bitcast (%struct.pair_of_float_nesting2_t* @a_pair_of_float_nesting2 to %3*), i32 0, i32 1), align 4
// RISCV64-LP64F-NEXT:    call void @pair_of_float_nesting2(float [[TMP0]], float [[TMP1]])
// RISCV64-LP64F-NEXT:    ret void
//
// RISCV64-LP64D-LABEL: @test_pair_of_float_nesting2(
// RISCV64-LP64D-NEXT:  entry:
// RISCV64-LP64D-NEXT:    [[TMP0:%.*]] = load float, float* getelementptr inbounds (%3, %3* bitcast (%struct.pair_of_float_nesting2_t* @a_pair_of_float_nesting2 to %3*), i32 0, i32 0), align 4
// RISCV64-LP64D-NEXT:    [[TMP1:%.*]] = load float, float* getelementptr inbounds (%3, %3* bitcast (%struct.pair_of_float_nesting2_t* @a_pair_of_float_nesting2 to %3*), i32 0, i32 1), align 4
// RISCV64-LP64D-NEXT:    call void @pair_of_float_nesting2(float [[TMP0]], float [[TMP1]])
// RISCV64-LP64D-NEXT:    ret void
//
void test_pair_of_float_nesting2(void) {
  pair_of_float_nesting2(a_pair_of_float_nesting2);
}

struct pair_of_float_nesting3_t {
  float a1[1];
  float a2[1];
} a_pair_of_float_nesting3;

void pair_of_float_nesting3(struct pair_of_float_nesting3_t);

struct pair_of_float_nesting4_t {
  float a1[1];
  struct {
    float b;
  } c;
} a_pair_of_float_nesting4;

void pair_of_float_nesting4(struct pair_of_float_nesting4_t);

// RISCV64-LP64-LABEL: @test_pair_of_float_nesting4(
// RISCV64-LP64-NEXT:  entry:
// RISCV64-LP64-NEXT:    [[TMP0:%.*]] = load i64, i64* bitcast (%struct.pair_of_float_nesting4_t* @a_pair_of_float_nesting4 to i64*), align 4
// RISCV64-LP64-NEXT:    call void @pair_of_float_nesting4(i64 [[TMP0]])
// RISCV64-LP64-NEXT:    ret void
//
// RISCV64-LP64F-LABEL: @test_pair_of_float_nesting4(
// RISCV64-LP64F-NEXT:  entry:
// RISCV64-LP64F-NEXT:    [[TMP0:%.*]] = load float, float* getelementptr inbounds (%4, %4* bitcast (%struct.pair_of_float_nesting4_t* @a_pair_of_float_nesting4 to %4*), i32 0, i32 0), align 4
// RISCV64-LP64F-NEXT:    [[TMP1:%.*]] = load float, float* getelementptr inbounds (%4, %4* bitcast (%struct.pair_of_float_nesting4_t* @a_pair_of_float_nesting4 to %4*), i32 0, i32 1), align 4
// RISCV64-LP64F-NEXT:    call void @pair_of_float_nesting4(float [[TMP0]], float [[TMP1]])
// RISCV64-LP64F-NEXT:    ret void
//
// RISCV64-LP64D-LABEL: @test_pair_of_float_nesting4(
// RISCV64-LP64D-NEXT:  entry:
// RISCV64-LP64D-NEXT:    [[TMP0:%.*]] = load float, float* getelementptr inbounds (%4, %4* bitcast (%struct.pair_of_float_nesting4_t* @a_pair_of_float_nesting4 to %4*), i32 0, i32 0), align 4
// RISCV64-LP64D-NEXT:    [[TMP1:%.*]] = load float, float* getelementptr inbounds (%4, %4* bitcast (%struct.pair_of_float_nesting4_t* @a_pair_of_float_nesting4 to %4*), i32 0, i32 1), align 4
// RISCV64-LP64D-NEXT:    call void @pair_of_float_nesting4(float [[TMP0]], float [[TMP1]])
// RISCV64-LP64D-NEXT:    ret void
//
void test_pair_of_float_nesting4(void) {
  pair_of_float_nesting4(a_pair_of_float_nesting4);
}

struct pair_of_float_nesting5_t {
  float a1[1];
  struct {
    float b;
  } c[1];
} a_pair_of_float_nesting5;

void pair_of_float_nesting5(struct pair_of_float_nesting5_t);

// RISCV64-LP64-LABEL: @test_pair_of_float_nesting5(
// RISCV64-LP64-NEXT:  entry:
// RISCV64-LP64-NEXT:    [[TMP0:%.*]] = load i64, i64* bitcast (%struct.pair_of_float_nesting5_t* @a_pair_of_float_nesting5 to i64*), align 4
// RISCV64-LP64-NEXT:    call void @pair_of_float_nesting5(i64 [[TMP0]])
// RISCV64-LP64-NEXT:    ret void
//
// RISCV64-LP64F-LABEL: @test_pair_of_float_nesting5(
// RISCV64-LP64F-NEXT:  entry:
// RISCV64-LP64F-NEXT:    [[TMP0:%.*]] = load float, float* getelementptr inbounds (%5, %5* bitcast (%struct.pair_of_float_nesting5_t* @a_pair_of_float_nesting5 to %5*), i32 0, i32 0), align 4
// RISCV64-LP64F-NEXT:    [[TMP1:%.*]] = load float, float* getelementptr inbounds (%5, %5* bitcast (%struct.pair_of_float_nesting5_t* @a_pair_of_float_nesting5 to %5*), i32 0, i32 1), align 4
// RISCV64-LP64F-NEXT:    call void @pair_of_float_nesting5(float [[TMP0]], float [[TMP1]])
// RISCV64-LP64F-NEXT:    ret void
//
// RISCV64-LP64D-LABEL: @test_pair_of_float_nesting5(
// RISCV64-LP64D-NEXT:  entry:
// RISCV64-LP64D-NEXT:    [[TMP0:%.*]] = load float, float* getelementptr inbounds (%5, %5* bitcast (%struct.pair_of_float_nesting5_t* @a_pair_of_float_nesting5 to %5*), i32 0, i32 0), align 4
// RISCV64-LP64D-NEXT:    [[TMP1:%.*]] = load float, float* getelementptr inbounds (%5, %5* bitcast (%struct.pair_of_float_nesting5_t* @a_pair_of_float_nesting5 to %5*), i32 0, i32 1), align 4
// RISCV64-LP64D-NEXT:    call void @pair_of_float_nesting5(float [[TMP0]], float [[TMP1]])
// RISCV64-LP64D-NEXT:    ret void
//
void test_pair_of_float_nesting5(void) {
  pair_of_float_nesting5(a_pair_of_float_nesting5);
}

struct float_and_double_t {
  float a;
  double b;
} a_float_and_double;

void float_and_double(struct float_and_double_t);

// RISCV64-LP64-LABEL: @test_float_and_double(
// RISCV64-LP64-NEXT:  entry:
// RISCV64-LP64-NEXT:    [[TMP0:%.*]] = load [2 x i64], [2 x i64]* bitcast (%struct.float_and_double_t* @a_float_and_double to [2 x i64]*), align 8
// RISCV64-LP64-NEXT:    call void @float_and_double([2 x i64] [[TMP0]])
// RISCV64-LP64-NEXT:    ret void
//
// RISCV64-LP64F-LABEL: @test_float_and_double(
// RISCV64-LP64F-NEXT:  entry:
// RISCV64-LP64F-NEXT:    [[TMP0:%.*]] = load [2 x i64], [2 x i64]* bitcast (%struct.float_and_double_t* @a_float_and_double to [2 x i64]*), align 8
// RISCV64-LP64F-NEXT:    call void @float_and_double([2 x i64] [[TMP0]])
// RISCV64-LP64F-NEXT:    ret void
//
// RISCV64-LP64D-LABEL: @test_float_and_double(
// RISCV64-LP64D-NEXT:  entry:
// RISCV64-LP64D-NEXT:    [[TMP0:%.*]] = load float, float* getelementptr inbounds (%6, %6* bitcast (%struct.float_and_double_t* @a_float_and_double to %6*), i32 0, i32 0), align 8
// RISCV64-LP64D-NEXT:    [[TMP1:%.*]] = load double, double* getelementptr inbounds (%6, %6* bitcast (%struct.float_and_double_t* @a_float_and_double to %6*), i32 0, i32 1), align 8
// RISCV64-LP64D-NEXT:    call void @float_and_double(float [[TMP0]], double [[TMP1]])
// RISCV64-LP64D-NEXT:    ret void
//
void test_float_and_double(void) {
  float_and_double(a_float_and_double);
}

struct float_and_double_nesting1_t {
  float a;
  struct {
    double b;
  } c[1];
} a_float_and_double_nesting1;

void float_and_double_nesting1(struct float_and_double_nesting1_t);

// RISCV64-LP64-LABEL: @test_float_and_double_nesting1(
// RISCV64-LP64-NEXT:  entry:
// RISCV64-LP64-NEXT:    [[TMP0:%.*]] = load [2 x i64], [2 x i64]* bitcast (%struct.float_and_double_nesting1_t* @a_float_and_double_nesting1 to [2 x i64]*), align 8
// RISCV64-LP64-NEXT:    call void @float_and_double_nesting1([2 x i64] [[TMP0]])
// RISCV64-LP64-NEXT:    ret void
//
// RISCV64-LP64F-LABEL: @test_float_and_double_nesting1(
// RISCV64-LP64F-NEXT:  entry:
// RISCV64-LP64F-NEXT:    [[TMP0:%.*]] = load [2 x i64], [2 x i64]* bitcast (%struct.float_and_double_nesting1_t* @a_float_and_double_nesting1 to [2 x i64]*), align 8
// RISCV64-LP64F-NEXT:    call void @float_and_double_nesting1([2 x i64] [[TMP0]])
// RISCV64-LP64F-NEXT:    ret void
//
// RISCV64-LP64D-LABEL: @test_float_and_double_nesting1(
// RISCV64-LP64D-NEXT:  entry:
// RISCV64-LP64D-NEXT:    [[TMP0:%.*]] = load float, float* getelementptr inbounds (%7, %7* bitcast (%struct.float_and_double_nesting1_t* @a_float_and_double_nesting1 to %7*), i32 0, i32 0), align 8
// RISCV64-LP64D-NEXT:    [[TMP1:%.*]] = load double, double* getelementptr inbounds (%7, %7* bitcast (%struct.float_and_double_nesting1_t* @a_float_and_double_nesting1 to %7*), i32 0, i32 1), align 8
// RISCV64-LP64D-NEXT:    call void @float_and_double_nesting1(float [[TMP0]], double [[TMP1]])
// RISCV64-LP64D-NEXT:    ret void
//
void test_float_and_double_nesting1(void) {
  float_and_double_nesting1(a_float_and_double_nesting1);
}

struct mixed_float_int_t {
    float a;
    int b;
} a_mixed_float_int;

void mixed_float_int(struct mixed_float_int_t);

// RISCV64-LP64-LABEL: @test_mixed_float_int(
// RISCV64-LP64-NEXT:  entry:
// RISCV64-LP64-NEXT:    [[TMP0:%.*]] = load i64, i64* bitcast (%struct.mixed_float_int_t* @a_mixed_float_int to i64*), align 4
// RISCV64-LP64-NEXT:    call void @mixed_float_int(i64 [[TMP0]])
// RISCV64-LP64-NEXT:    ret void
//
// RISCV64-LP64F-LABEL: @test_mixed_float_int(
// RISCV64-LP64F-NEXT:  entry:
// RISCV64-LP64F-NEXT:    [[TMP0:%.*]] = load float, float* getelementptr inbounds (%6, %6* bitcast (%struct.mixed_float_int_t* @a_mixed_float_int to %6*), i32 0, i32 0), align 4
// RISCV64-LP64F-NEXT:    [[TMP1:%.*]] = load i32, i32* getelementptr inbounds (%6, %6* bitcast (%struct.mixed_float_int_t* @a_mixed_float_int to %6*), i32 0, i32 1), align 4
// RISCV64-LP64F-NEXT:    call void @mixed_float_int(float [[TMP0]], i32 signext [[TMP1]])
// RISCV64-LP64F-NEXT:    ret void
//
// RISCV64-LP64D-LABEL: @test_mixed_float_int(
// RISCV64-LP64D-NEXT:  entry:
// RISCV64-LP64D-NEXT:    [[TMP0:%.*]] = load float, float* getelementptr inbounds (%8, %8* bitcast (%struct.mixed_float_int_t* @a_mixed_float_int to %8*), i32 0, i32 0), align 4
// RISCV64-LP64D-NEXT:    [[TMP1:%.*]] = load i32, i32* getelementptr inbounds (%8, %8* bitcast (%struct.mixed_float_int_t* @a_mixed_float_int to %8*), i32 0, i32 1), align 4
// RISCV64-LP64D-NEXT:    call void @mixed_float_int(float [[TMP0]], i32 signext [[TMP1]])
// RISCV64-LP64D-NEXT:    ret void
//
void test_mixed_float_int(void)
{
    mixed_float_int(a_mixed_float_int);
}

struct mixed_float_short_t {
    float a;
    unsigned short b;
} a_mixed_float_short;

void mixed_float_short(struct mixed_float_short_t, short c);

// RISCV64-LP64-LABEL: @test_mixed_float_short(
// RISCV64-LP64-NEXT:  entry:
// RISCV64-LP64-NEXT:    [[S:%.*]] = alloca i16, align 2
// RISCV64-LP64-NEXT:    store i16 1, i16* [[S]], align 2
// RISCV64-LP64-NEXT:    [[TMP0:%.*]] = load i16, i16* [[S]], align 2
// RISCV64-LP64-NEXT:    [[TMP1:%.*]] = load i64, i64* bitcast (%struct.mixed_float_short_t* @a_mixed_float_short to i64*), align 4
// RISCV64-LP64-NEXT:    call void @mixed_float_short(i64 [[TMP1]], i16 signext [[TMP0]])
// RISCV64-LP64-NEXT:    ret void
//
// RISCV64-LP64F-LABEL: @test_mixed_float_short(
// RISCV64-LP64F-NEXT:  entry:
// RISCV64-LP64F-NEXT:    [[S:%.*]] = alloca i16, align 2
// RISCV64-LP64F-NEXT:    store i16 1, i16* [[S]], align 2
// RISCV64-LP64F-NEXT:    [[TMP0:%.*]] = load i16, i16* [[S]], align 2
// RISCV64-LP64F-NEXT:    [[TMP1:%.*]] = load float, float* getelementptr inbounds (%7, %7* bitcast (%struct.mixed_float_short_t* @a_mixed_float_short to %7*), i32 0, i32 0), align 4
// RISCV64-LP64F-NEXT:    [[TMP2:%.*]] = load i16, i16* getelementptr inbounds (%7, %7* bitcast (%struct.mixed_float_short_t* @a_mixed_float_short to %7*), i32 0, i32 1), align 4
// RISCV64-LP64F-NEXT:    call void @mixed_float_short(float [[TMP1]], i16 zeroext [[TMP2]], i16 signext [[TMP0]])
// RISCV64-LP64F-NEXT:    ret void
//
// RISCV64-LP64D-LABEL: @test_mixed_float_short(
// RISCV64-LP64D-NEXT:  entry:
// RISCV64-LP64D-NEXT:    [[S:%.*]] = alloca i16, align 2
// RISCV64-LP64D-NEXT:    store i16 1, i16* [[S]], align 2
// RISCV64-LP64D-NEXT:    [[TMP0:%.*]] = load i16, i16* [[S]], align 2
// RISCV64-LP64D-NEXT:    [[TMP1:%.*]] = load float, float* getelementptr inbounds (%9, %9* bitcast (%struct.mixed_float_short_t* @a_mixed_float_short to %9*), i32 0, i32 0), align 4
// RISCV64-LP64D-NEXT:    [[TMP2:%.*]] = load i16, i16* getelementptr inbounds (%9, %9* bitcast (%struct.mixed_float_short_t* @a_mixed_float_short to %9*), i32 0, i32 1), align 4
// RISCV64-LP64D-NEXT:    call void @mixed_float_short(float [[TMP1]], i16 zeroext [[TMP2]], i16 signext [[TMP0]])
// RISCV64-LP64D-NEXT:    ret void
//
void test_mixed_float_short(void)
{
    short s = 1;
    mixed_float_short(a_mixed_float_short, s);
}

struct mixed_double_short_t {
    double a;
    unsigned short b;
} a_mixed_double_short;

void mixed_double_short(struct mixed_double_short_t, short c);

// RISCV64-LP64-LABEL: @test_mixed_double_short(
// RISCV64-LP64-NEXT:  entry:
// RISCV64-LP64-NEXT:    [[S:%.*]] = alloca i16, align 2
// RISCV64-LP64-NEXT:    store i16 1, i16* [[S]], align 2
// RISCV64-LP64-NEXT:    [[TMP0:%.*]] = load i16, i16* [[S]], align 2
// RISCV64-LP64-NEXT:    [[TMP1:%.*]] = load [2 x i64], [2 x i64]* bitcast (%struct.mixed_double_short_t* @a_mixed_double_short to [2 x i64]*), align 8
// RISCV64-LP64-NEXT:    call void @mixed_double_short([2 x i64] [[TMP1]], i16 signext [[TMP0]])
// RISCV64-LP64-NEXT:    ret void
//
// RISCV64-LP64F-LABEL: @test_mixed_double_short(
// RISCV64-LP64F-NEXT:  entry:
// RISCV64-LP64F-NEXT:    [[S:%.*]] = alloca i16, align 2
// RISCV64-LP64F-NEXT:    store i16 1, i16* [[S]], align 2
// RISCV64-LP64F-NEXT:    [[TMP0:%.*]] = load i16, i16* [[S]], align 2
// RISCV64-LP64F-NEXT:    [[TMP1:%.*]] = load [2 x i64], [2 x i64]* bitcast (%struct.mixed_double_short_t* @a_mixed_double_short to [2 x i64]*), align 8
// RISCV64-LP64F-NEXT:    call void @mixed_double_short([2 x i64] [[TMP1]], i16 signext [[TMP0]])
// RISCV64-LP64F-NEXT:    ret void
//
// RISCV64-LP64D-LABEL: @test_mixed_double_short(
// RISCV64-LP64D-NEXT:  entry:
// RISCV64-LP64D-NEXT:    [[S:%.*]] = alloca i16, align 2
// RISCV64-LP64D-NEXT:    store i16 1, i16* [[S]], align 2
// RISCV64-LP64D-NEXT:    [[TMP0:%.*]] = load i16, i16* [[S]], align 2
// RISCV64-LP64D-NEXT:    [[TMP1:%.*]] = load double, double* getelementptr inbounds (%10, %10* bitcast (%struct.mixed_double_short_t* @a_mixed_double_short to %10*), i32 0, i32 0), align 8
// RISCV64-LP64D-NEXT:    [[TMP2:%.*]] = load i16, i16* getelementptr inbounds (%10, %10* bitcast (%struct.mixed_double_short_t* @a_mixed_double_short to %10*), i32 0, i32 1), align 8
// RISCV64-LP64D-NEXT:    call void @mixed_double_short(double [[TMP1]], i16 zeroext [[TMP2]], i16 signext [[TMP0]])
// RISCV64-LP64D-NEXT:    ret void
//
void test_mixed_double_short(void)
{
    short s = 1;
    mixed_double_short(a_mixed_double_short, s);
}
